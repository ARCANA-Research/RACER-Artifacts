/*
This microkernel convolute K (8-bit 2x2 matrix) with 2048 RGB images,
each image is 8-bit 128x128 matrix

See 8bconv2x2.rc for general setup

*/
/*============================= MAIN PROGRAM =================================*/
/*
  (*) Turn on all 4096 clusters to convolve 2048 images (2 cluster per image)
  (*) RGB conv simply have 3 times number of input data compared to grayscale conv
  (*) Grayscale conv can store 4x3 vectors output in 1 compute unit
  (*) RGB instead only store 3x3 vectors in 1 compute unit (3 per conv layer)
  ->  So 22 x 4 = 88 compute units are needed (44 per cluster)
  (*) A final additional sum up the result of each conv layer. The addition is
  internal to the compute unit. The following illustrate where data are stored:

  [                             COMPUTE UNIT                                 ]
  [   3rd halfset   ][   2nd halfset   ][   1st halfset   ][   0th halfset   ]

  [    ADD result   ][<- R layer result][<- G layer result][<- B layer result]

  (*) Data shifting from different halfset takes different amount of latency
  (*) The conv output is in Z-format
  (*) The last argument of all compute instruction is a simulated-level argument,
      and it represents an energy multiplicative factor. Because a multiword can
      be broken down into multiple compute engine doing the same thing, the multiplicative
      factor is a quick way to calculate the energy consumption of multiple engines.
      Because all engines operate in parallel, there is not equivalent factor for latency.
  (*) Every pipeline instruction (ADD16 in this case) has its argument
    represented with 'x'. This is because the simulator treat multiple additions
    in the same pipeline as 1 instruction (so that it doesnt have to simulate
    the pipeline). An additional argument is then needed for piplined instruction
    because we need to specify how many additions are there in the pipeline fleet.
    So for a fleet of 3 addition:
      - ADD16 h12 h23 h2
      - ADD16 h12 h12 h28
      - ADD16 h12 h53 h29
    Write it as:
      - ADD16 x x x 3
    The simulator right now only consider performance, so the operands are
    omitted anyway (even for non pipelined instructions)
  (*) Because each layer produce 3 results in 1 compute units, the final addition
      fleet size is 9
  (*) The SHIFT instruction (within compute unit) is not supported by the
      simulator for now. Bulk shifting is complicated to get correctly.
      Instead, hand calculate the cost (latency, energy) for each specific
      shift so that the simulator can add it in final cost (TODO)
  (*) There are 3 shifts before the final addition:
      1st SHIFT:
          - Shift R layer into 3rd halfset (addition engine)
          - Shift G layer into 2nd halfset
          - Shift B layer into 1st halfset
          -> (16 + 15 + 14 + ... + 1) x 3 x 3 = 1224 SHIFT
      2nd SHIFT:
          - Shift G into addition engine (R is already in-place)
          - Shift B into 2nd halfset
          -> (16 + 15 + 14 + ... + 1) x 2 x 3  = 816 SHIFT
      3rd SHIFT:
          - Shift B into addition engine
          -> (16 + 15 + 14 + ... + 1) x 3 = 408 SHIFT
   (*) A single 64-bit vector SHIFT (latch into buffer, latch from buffer) has a
       cost of (taken from device-level simulation of a LATCH operation):
          - Latency = 2 x 5.281 = 10.562 (ns)
          - Energy  = 2 x 1.6384 = 3.2768 (pJ)
       The SHIFT cost can be calculated accordingly
*/

// TODO Change this to a for loop
SETBULK 0 4096 64
SETBULK 1 4096 64
SETBULK 2 4096 64
SETBULK 3 4096 64
SETBULK 4 4096 64
SETBULK 5 4096 64
SETBULK 6 4096 64
SETBULK 7 4096 64
SETBULK 8 4096 64
SETBULK 9 4096 64
SETBULK 10 4096 64
SETBULK 11 4096 64
SETBULK 12 4096 64
SETBULK 13 4096 64
SETBULK 14 4096 64
SETBULK 15 4096 64
SETBULK 16 4096 64
SETBULK 17 4096 64
SETBULK 18 4096 64
SETBULK 19 4096 64
SETBULK 20 4096 64
SETBULK 21 4096 64
SETBULK 22 4096 64
SETBULK 23 4096 64
SETBULK 24 4096 64
SETBULK 25 4096 64
SETBULK 26 4096 64
SETBULK 27 4096 64
SETBULK 28 4096 64
SETBULK 29 4096 64
SETBULK 30 4096 64
SETBULK 31 4096 64
SETBULK 32 4096 64
SETBULK 33 4096 64
SETBULK 34 4096 64
SETBULK 35 4096 64
SETBULK 36 4096 64
SETBULK 37 4096 64
SETBULK 38 4096 64
SETBULK 39 4096 64
SETBULK 40 4096 64
SETBULK 41 4096 64
SETBULK 42 4096 64
SETBULK 43 4096 64

//18 <- 17 16 15 14 13 12 11 10 9
MAC16 h0v18 b0v9 b0v0 4
MAC16 h0v18 b0v10 b0v1 4
MAC16 h0v18 b0v11 b0v2 4
MAC16 h0v18 b0v12 b0v3 4
MAC16 h0v18 b0v13 b0v4 4
MAC16 h0v18 b0v14 b0v5 4
MAC16 h0v18 b0v15 b0v6 4
MAC16 h0v18 b0v16 b0v7 4
MAC16 h0v18 b0v17 b0v8 4

//28 <- 27 26 25 24 23 22 21 20 19
MAC16 h0v28 b0v19 b0v0 4
MAC16 h0v28 b0v20 b0v1 4
MAC16 h0v28 b0v21 b0v2 4
MAC16 h0v28 b0v22 b0v3 4
MAC16 h0v28 b0v23 b0v4 4
MAC16 h0v28 b0v24 b0v5 4
MAC16 h0v28 b0v25 b0v6 4
MAC16 h0v28 b0v26 b0v7 4
MAC16 h0v28 b0v27 b0v8 4

//38 <- 37 36 35 34 33 32 31 30 29
MAC16 h0v38 b0v29 b0v0 4
MAC16 h0v38 b0v30 b0v1 4
MAC16 h0v38 b0v31 b0v2 4
MAC16 h0v38 b0v32 b0v3 4
MAC16 h0v38 b0v33 b0v4 4
MAC16 h0v38 b0v34 b0v5 4
MAC16 h0v38 b0v35 b0v6 4
MAC16 h0v38 b0v36 b0v7 4
MAC16 h0v38 b0v37 b0v8 4

// Shift R Layer into 3rd halfset
SHIFT 506.976 16428249.9072

// Shift G Layer into 3rd halfset
SHIFT 506.976 10952166.6048

// Shift B Layer into 3rd halfset
SHIFT 506.976 5476083.3024

// Final Addition
ADD16 x x x 9 1

UNSETALL
